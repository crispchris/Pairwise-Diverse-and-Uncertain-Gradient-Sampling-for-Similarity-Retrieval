# PairDUG-Sampling for Similarity Retrieval

This repository implements the **Pairwise Diverse and Uncertain Gradient** (PairDUG) method introduced in:

Christoffer LÃ¶ffler,  *Pairwise Diverse and Uncertain Gradient-Sampling for Similarity Retrieval*  
*Sensors* **2025**, 25(22), 6899. [https://doi.org/10.3390/s25226899](https://doi.org/10.3390/s25226899)

It provides a reproducible PyTorch implementation for *pairwise retrieval learning* using gradient-based active selection and gradient diagnostics.


![Figure 1: System Diagram](figure1.png)


## ğŸ“ Project Structure

```
â”œâ”€â”€ main.py                  # Main training and active learning loop (Hydra + MLflow)
â”œâ”€â”€ model.py                 # Siamese network, custom embedding loss, and MAPE metric
â”œâ”€â”€ data_module.py           # Torch Dataset and DataLoader utilities
â”œâ”€â”€ cost_fns.py              # Hungarian and keypoint-based cost functions
â”œâ”€â”€ retrieval_metrics.py     # Retrieval and ranking evaluation metrics (Recall/Precision, mAP, nDCG, MSRCC)
â”œâ”€â”€ gradient_metrics.py      # Per-example gradient diagnostics
â”œâ”€â”€ conf/
â”‚   â””â”€â”€ config.yaml          # Experiment configuration (Hydra)
```

---

## ğŸš€ Overview

The framework trains a **Siamese neural network** to estimate similarity between spatiotemporal sports events (e.g., football or basketball plays). It supports multiple **active data selection** strategies and evaluates retrieval quality via *metric-learning* objectives.

### Key Concepts
- **Pairwise similarity learning** via Hungarian costs between event trajectories.
- **PairDUG sampling** using gradient diversity and uncertainty.
- **Retrieval evaluation** using Precision@K, Recall@K, mAP@K, nDCG@K, Mean Spearman Rank Correlation Coefficient (MSRCC) and MAPE.
- **Gradient diagnostics** to measure batch informativeness: mean norm, diversity, rank, signal-to-noise ratio.

---

## âš™ï¸ Installation

```bash
git clone git@github.com:crispchris/Pairwise-Diverse-and-Uncertain-Gradient-Sampling-for-Similarity-Retrieval.git PairDUG
cd PairDUG
pip install -r requirements.txt
```

**Core dependencies:**  
`torch`, `numpy`, `scipy`, `scikit-learn`, `tqdm`, `hydra-core`, `omegaconf`, `mlflow`


## ğŸ§© Dataset Creation

Data come from **NBA SportVU** ([linouk23/NBA-Player-Movements](https://github.com/linouk23/NBA-Player-Movements)) and **NFL Nextâ€¯Genâ€¯Stats** ([asonty/ngs_highlights](https://github.com/asonty/ngs_highlights)).  
Each pipeline converts raw tracking data into fixedâ€‘length event tensors, then builds pairwise samples with Hungarian alignment costs.

For basketball, raw SportVU JSON logs (compressed `.7z` archives) were parsed into per-play tensors of shape *(2,â€¯11,â€¯150)*, representing 11 tracked entities (10 playersâ€¯+â€¯ball) with x/y positions over 150 frames. Invalid or duplicate plays were filtered, and the remaining events were split into train/validation/test partitions.  

For football, NGS play-level TSV files were normalized into tensors of shape *(2,â€¯23,â€¯50)*, capturing 22 playersâ€¯+â€¯ball over 50 frames. Sliding windows and padding ensured consistent temporal coverage across plays.  

In both sports, **pairwise training samples** were generated by randomly selecting event pairs and computing **Hungarian alignment costs** between trajectories, producing triplets *(i,â€¯j,â€¯cost)*. These were serialized into `.pt` tensors (`pairs_train.pt`, `pairs_val.pt`, `pairs_test.pt`) used for similarity learning and retrieval evaluation.

---

### ğŸ€ NBA SportVU

1. **Convert raw JSON logs**  
   ```bash
   python 01_nba_to_torch.py
   ```  
   â†’ Produces `nba_sportvu_train.pt`, `nba_sportvu_val.pt`, `nba_sportvu_test.pt` (events of shapeâ€¯`(2,â€¯11,â€¯150)`).

2. **Sample event pairs**  
   ```bash
   python 02_nba_sample_pairs.py
   ```  
   â†’ Generates `pairs_train_10M.pt`, `pairs_val_10M.pt`, `pairs_test_10M.pt` with `(i,â€¯j,â€¯cost)` triplets.

---

### ğŸˆ NFL Nextâ€¯Genâ€¯Stats

1. **Convert raw TSV plays**  
   ```bash
   python 01_nfl_to_torch.py
   ```  
   â†’ Produces `nfl_ngs_train.pt`, `nfl_ngs_val.pt`, `nfl_ngs_test.pt` (events of shapeâ€¯`(2,â€¯23,â€¯50)`).

2. **Sample event pairs**  
   ```bash
   python 02_nfl_sample_pairs.py
   ```  
   â†’ Outputs `pairs_nfl_train_100k.pt`, `pairs_nfl_val_100k.pt`, `pairs_nfl_test_100k.pt`.

---

---

## ğŸ§  Usage

### 1. Configure your experiment
Edit [`conf/config.yaml`](conf/config.yaml) to set:
- dataset paths (`train_pairs`, `train_events`, etc.)
- `sport`: `basketball` or `football`
- `active_strategy`: `badge_fast`, `random`, `full`, etc.
- training hyperparameters: epochs, learning rate, early stopping.

### 2. Run training
```bash
python main.py
```

Example:
```bash
python main.py active_strategy=badge_fast sport=football epochs=300
```
---

## ğŸ“Š MLflow Logging

Each run logs:
- Training, validation, and test metrics (`loss`, `mape`)
- Gradient metrics (`grad_mean_norm`, `grad_diversity`, `grad_snr`, `grad_rank`)
- Retrieval metrics (`Recall@K`, `mAP@K`, `nDCG@K`, `MSRCC`)
- Early stopping and hyperparameters

View results:
```bash
mlflow ui
```
Then open [http://localhost:5000](http://localhost:5000).

---

## ğŸ§± Citation

If you use this repository, please cite:
```
@article{Loffler2025Pairwise,
  author    = {Christoffer L{\"o}ffler},
  title     = {Pairwise Diverse and Uncertain Gradient-Sampling for Similarity Retrieval},
  journal   = {Sensors},
  year      = {2025},
  volume    = {25},
  number    = {22},
  pages     = {6899},
  doi       = {10.3390/s25226899},
  url       = {https://doi.org/10.3390/s25226899}
}
```
